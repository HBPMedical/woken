# Sample configuration for local execution of woken

akka {
  loglevel = DEBUG
  stdout-loglevel = WARNING

  log-config-on-start = on
  log-dead-letters = 1
  log-dead-letters-during-shutdown = off

  # a nice way to prevent cold start of extension is to define it to be loaded on actor system start
  # extensions += "com.github.levkhomich.akka.tracing.TracingExtension"

  tracing {
    # use this option to disable tracing
    #    enabled = off

    # zipkin collector or scribe host name
    host = "zipkin"

    # collector's port
    #    port = 9410 # default, can be omitted

    # every n'th message should be traced
    # for example, 1 means that every message would be traced, 2 - half of messages, 4 - a fourth part, etc.
    sample-rate = 1
  }

  remote {
    log-sent-messages = off
    log-received-messages = off
    log-remote-lifecycle-events = off

    maximum-payload-bytes = 10000000 bytes

    netty.tcp {
      hostname = ${clustering.ip} # external (logical) hostname
      port = ${clustering.port}   # external (logical) port

      bind.hostname = 0.0.0.0         # internal (bind) hostname
      bind.port = ${clustering.port}  # internal (bind) port

      message-frame-size =  10000000b
      send-buffer-size =  10000000b
      receive-buffer-size =  10000000b
      maximum-frame-size = 10000000b
    }

    //    artery {
    //      enabled = off
    //      canonical.hostname = ${clustering.ip} # external (logical) hostname
    //      canonical.port = ${clustering.port}   # external (logical) port
    //
    //      bind.hostname = 0.0.0.0         # internal (bind) hostname
    //      bind.port = ${clustering.port}  # internal (bind) port
    //
    //      advanced.aeron-dir = "/dev/shm/woken"
    //    }
  }

  cluster {
    seed-nodes = [
      "akka.tcp://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}
    ]

    roles = ["woken"]

    role {
      woken.min-nr-of-members = 1
      validation.min-nr-of-members = 1
      scoring.min-nr-of-members = 1
    }

    client {
      initial-contacts = ["akka.tcp://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}"/system/receptionist"]
    }

  }
}

app {
  clusterSystemName = ${clustering.cluster.name}
  jobServiceName = "job-service"
  dockerBridgeNetwork = "tests_default"
  networkInterface = "0.0.0.0"
  webServicesPort = 8087
  webServicesHttps = off

  master.router {
    actors {
      mining.limit = 10
      experiment.limit = 10
    }
  }

  basicAuth {
    user = "admin"
    password = "WoKeN"
  }
}

jobs {
  node = "federation"
  owner = "admin@mip.chuv.ch"
  chronosServerUrl = "http://chronos:4400"
  featuresDb = "features"
  featuresTable = "cde_features_a"
  resultDb = "woken"
  metaDb = "meta"
}

db {
  woken {
    jdbc_driver = "org.postgresql.Driver"
    jdbc_url = "jdbc:postgresql://db:5432/woken"
    host = "db"
    port = 5432
    user = "postgres"
    password = "test"
  }

  features {
    jdbc_driver = "org.postgresql.Driver"
    jdbc_url = "jdbc:postgresql://db:5432/features"
    host = "db"
    port = 5432
    user = "postgres"
    password = "test"
  }

  meta {
    jdbc_driver = "org.postgresql.Driver"
    jdbc_url = "jdbc:postgresql://db:5432/meta"
    host = "db"
    port = 5432
    user = "postgres"
    password = "test"
  }

}

datasets {

  sample {
    label = "Sample data"
    description = "Sample data"
    tables = ["sample_data"]
    anonymisationLevel = "Anonymised"
  }

  churn {
    label = "Customer churn"
    description = "Customer churn"
    tables = ["churn"]
    anonymisationLevel = "Anonymised"
  }

  chuv {
    label = "CHUV"
    description = "Demo dataset for CHUV"
    tables = ["cde_features_a"]
    anonymisationLevel = "Anonymised"
  }

  brescia {
    label = "Brescia"
    description = "Brescia demo"
    tables = ["cde_features_b"]
    anonymisationLevel = "Depersonalised"
  }

  lille {
    label = "Lille"
    description = "Lille demo"
    tables = ["cde_features_c"]
    anonymisationLevel = "Depersonalised"
  }

}

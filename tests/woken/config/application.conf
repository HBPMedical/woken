
# Sample configuration for local execution of woken

akka {
  loglevel = DEBUG
  stdout-loglevel = WARNING
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  log-dead-letters = 10

  # a nice way to prevent cold start of extension is to define it to be loaded on actor system start
  # extensions += "com.github.levkhomich.akka.tracing.TracingExtension"

  tracing {
    # use this option to disable tracing
    #    enabled = off

    # zipkin collector or scribe host name
    host = "zipkin"

    # collector's port
    #    port = 9410 # default, can be omitted

    # every n'th message should be traced
    # for example, 1 means that every message would be traced, 2 - half of messages, 4 - a fourth part, etc.
    sample-rate = 1
  }

  actor {
    provider = "cluster"
    enable-additional-serialization-bindings = on

    debug {
      receive = on
      autoreceive = off
      lifecycle = on
      fsm = on
      unhandled = on
      event-stream = off
    }

    serializers {
      query-result-serializer = "eu.hbp.mip.woken.messages.external.QueryResultSerializer"
    }

    serialization-bindings {
      "eu.hbp.mip.woken.messages.external.QueryResult" = query-result-serializer
    }

    # Actors created by Akka automatically
    deployment {

      /entrypoint/mainRouter/validationWorker {
        router = random-group
        routees.paths = ["/user/validation"]
        cluster {
          enabled = on
          allow-local-routees = off
          use-roles = ["validation"]
        }
      }

      /entrypoint/mainRouter/scoringWorker {
        router = random-group
        routees.paths = ["/user/scoring"]
        cluster {
          enabled = on
          allow-local-routees = off
          use-roles = ["scoring"]
        }
      }

    }
  }

  remote {
    log-sent-messages = off
    log-received-messages = off
    log-remote-lifecycle-events = off

    maximum-payload-bytes = 10000000 bytes

    netty.tcp {
      hostname = ${clustering.ip} # external (logical) hostname
      port = ${clustering.port}   # external (logical) port

      bind.hostname = 0.0.0.0         # internal (bind) hostname
      bind.port = ${clustering.port}  # internal (bind) port
    }

    artery {
      enabled = off
      canonical.hostname = ${clustering.ip} # external (logical) hostname
      canonical.port = ${clustering.port}   # external (logical) port

      bind.hostname = 0.0.0.0         # internal (bind) hostname
      bind.port = ${clustering.port}  # internal (bind) port

      advanced.aeron-dir = "/dev/shm/woken"
    }
  }

  extensions += "akka.cluster.pubsub.DistributedPubSub"
  extensions += "akka.cluster.client.ClusterClientReceptionist"

  cluster {
    seed-nodes = [
      "akka.tcp://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}
    ]

    roles = ["woken"]

    role {
      woken.min-nr-of-members = 1
      validation.min-nr-of-members = 1
      scoring.min-nr-of-members = 1
    }

    client {
      initial-contacts = ["akka.tcp://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}"/system/receptionist"]
    }

  }
}

akka.http {
  server {
    idle-timeout = 300s
    request-timeout = 180s
    ssl-encryption = off
    ssl-tracing = on
  }

  client {
    idle-timeout = 300s
    request-timeout = 20 s
  }
}

clustering {
  ip = "127.0.0.1"
  ip = ${?CLUSTER_IP}
  port = 8088
  port = ${?CLUSTER_PORT}
  seed-ip = "127.0.0.1"
  seed-ip = ${?CLUSTER_IP}
  seed-ip = ${?WOKEN_PORT_8088_TCP_ADDR}
  seed-port = 8088
  seed-port = ${?WOKEN_PORT_8088_TCP_PORT}
  cluster.name = "woken"
  cluster.name = ${?CLUSTER_NAME}
}

app {
  clusterSystemName = ${clustering.cluster.name}
  jobServiceName = "job-service"
  dockerBridgeNetwork = "tests_default"
  networkInterface = "0.0.0.0"
  webServicesPort = 8087
  webServicesHttps = off

  master.router {
    actors {
      mining.limit = 10
      experiment.limit = 10
    }
  }

  basicAuth {
    user = "admin"
    password = "WoKeN"
  }
}

jobs {
  node = "federation"
  owner = "admin@mip.chuv.ch"
  chronosServerUrl = "http://chronos:4400"
  featuresDb = "features"
  featuresTable = "sample_data"
  resultDb = "woken"
  metaDb = "metadata"
}

db {
  woken {
    jdbc_driver = "org.postgresql.Driver"
    jdbc_url    = "jdbc:postgresql://db:5432/woken"
    host = "db"
    port = 5432
    user = "postgres"
    password = "test"
  }

  features {
    jdbc_driver = "org.postgresql.Driver"
    jdbc_url    = "jdbc:postgresql://db:5432/features"
    host = "db"
    port = 5432
    user = "postgres"
    password = "test"
  }

  metadata {
    jdbc_driver = "org.postgresql.Driver"
    jdbc_url    = "jdbc:postgresql://db:5432/meta"
    host = "db"
    port = 5432
    user = "postgres"
    password = "test"
  }

}

# The actual Algorithm Library
algorithms {
  histograms {
    dockerImage = "hbpmip/python-histograms:0.3.6"
    predictive = false
    supportsNullValues = true
  }
  statisticsSummary {
    dockerImage = "hbpmip/r-summary-stats:2afe249"
    predictive = false
    supportsNullValues = true
  }
  anova {
    dockerImage = "hbpmip/python-anova:0.3.5"
    predictive = false
    supportsNullValues = false
  }
  linearRegression {
    dockerImage = "hbpmip/python-linear-regression:0.0.6"
    predictive = false
    supportsNullValues = false
  }
  knn {
    dockerImage = "hbpmip/java-rapidminer-knn:0.2.1"
    predictive = true
    supportsNullValues = false
  }
  naiveBayes {
    dockerImage = "hbpmip/java-rapidminer-naivebayes:0.2.0"
    predictive = true
    supportsNullValues = false
  }
  tSNE {
    image = "hbpmip/python-tsne:0.3.3"
    predictive = false
    supportsNullValues = false
    maturity = "experimental"
  }
  ggparci {
    dockerImage = "hbpmip/r-ggparci:0.2.0"
    predictive = false
    supportsNullValues = false
    maturity = "experimental"
  }
  # Only for testing
  chaos {
    dockerImage = "hbpmip/chaos-algorithm:0.1.1"
    predictive = true
    supportsNullValues = true
  }
}

datasets {

  sample {
    label = "Sample data"
    description = "Sample data"
    tables = ["sample_data"]
    anonymisationLevel = "Anonymised"
  }

  churn {
    label = "Customer churn"
    description = "Customer churn"
    tables = ["churn"]
    anonymisationLevel = "Anonymised"
  }

}
